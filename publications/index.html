<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Yash Mehta</title> <meta name="author" content="Yash Mehta"/> <meta name="description" content="Personal website"/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/nn_logo_color.png"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://yashsmehta.github.io/publications/"> <link rel="stylesheet" href="https://use.typekit.net/vxy8tas.css"> <style>#network-animation{position:fixed;top:0;left:0;width:100vw;height:100vh;z-index:-1;opacity:.6;background:white;pointer-events:none}body{position:relative;min-height:100vh;background:transparent!important;font-family:"proxima-nova",sans-serif;font-weight:300}h1,h2,h3,h4,h5,h6{font-family:"factoria",sans-serif;font-weight:700}strong,b{font-weight:700}em,i{font-style:italic}.navbar-nav .nav-link{font-family:"factoria",sans-serif;font-weight:300;color:#002d72!important}.navbar-brand{font-family:"factoria",sans-serif;font-weight:300}.dropdown-item{font-family:"factoria",sans-serif;font-weight:300}.container.mt-5,header .container{max-width:750px!important;width:60%;margin-left:auto;margin-right:auto}.container.mt-5{background:rgba(255,255,255,0.6);backdrop-filter:blur(10px);-webkit-backdrop-filter:blur(10px);border-radius:10px;padding:1.5rem 2rem;box-shadow:0 4px 6px rgba(0,0,0,0.1);margin-top:1.5rem!important}header.fixed-top{background:rgba(255,255,255,0.6)!important;backdrop-filter:blur(10px);-webkit-backdrop-filter:blur(10px)}footer{background:rgba(255,255,255,0.6)!important;backdrop-filter:blur(10px);-webkit-backdrop-filter:blur(10px)}@media(max-width:768px){html,body{overflow-x:hidden!important;width:100%!important}#network-animation{display:none!important}.container.mt-5,header .container{width:100%!important;max-width:100%!important;padding-left:14px!important;padding-right:14px!important;box-sizing:border-box!important}.container.mt-5{margin-top:.75rem!important}.container.mt-5{background:white!important;backdrop-filter:none!important;-webkit-backdrop-filter:none!important;box-shadow:none!important;border-radius:0!important}header.fixed-top{background:white!important;backdrop-filter:none!important;-webkit-backdrop-filter:none!important}}</style> </head> <body class="fixed-top-nav sticky-bottom-footer"> <canvas id="network-animation"></canvas> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="nav-link" href="mailto:yashsmehta95@gmail.com" style="padding-left: 0; padding-right: 0.75rem;"> <i class="fas fa-envelope"></i> </a> <a class="navbar-brand title font-weight-lighter" href="/">Yash Mehta</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Code</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <style>.publications{margin-top:2rem;display:grid;gap:1.5rem}.publication-item{display:flex;padding:.8rem;border-radius:12px;transition:all .3s ease;font-size:.95rem;border-left:4px solid transparent;background:white;box-shadow:0 2px 4px rgba(0,0,0,0.04);height:140px;overflow:hidden}.publication-item:hover{box-shadow:0 4px 8px rgba(0,0,0,0.08);transform:translateY(-2px)}.pub-image{width:160px;min-width:160px;margin-right:1.2rem;aspect-ratio:16/9}.pub-image img{width:100%;height:100%;object-fit:cover;border-radius:8px;box-shadow:0 2px 4px rgba(0,0,0,0.1)}.preview-placeholder{width:100%;height:100%;background:#f5f5f5;border-radius:8px;display:flex;align-items:center;justify-content:center}.preview-placeholder::after{content:'ðŸ“„';font-size:2.5rem;color:#ddd}.pub-content{flex:1;min-width:0;display:flex;flex-direction:column}.title-row{display:flex;align-items:flex-start;gap:.8rem;margin-bottom:.15rem}.title-row .title{font-family:"factoria",sans-serif;font-weight:500;color:#2c3e50;font-size:1rem;line-height:1.2;flex:1}.topic-icon{display:inline-flex;align-items:center;justify-content:center;width:1.6rem;height:1.6rem;border-radius:50%;font-size:.9rem;flex-shrink:0}.pub-content .author{font-family:"proxima-nova",sans-serif;font-weight:300;color:#666;margin-bottom:.3rem;font-size:.9rem;line-height:1.2}.pub-content .periodical{font-family:"proxima-nova",sans-serif;font-weight:300;margin-top:.1rem;font-size:.9rem;margin-bottom:.3rem;line-height:1.3;display:flex;align-items:center;gap:.4rem;flex-wrap:wrap}.pub-content .periodical .venue{color:#68ace5}.pub-content .periodical .venue em{font-family:"proxima-nova",sans-serif;font-style:normal;font-weight:500}.pub-content .periodical .year{color:#666;font-weight:600}.pub-links{display:flex;flex-wrap:wrap;gap:.4rem;margin-top:auto;padding-bottom:.2rem}.pub-links a,.abstract-toggle{font-family:"proxima-nova",sans-serif;font-weight:300;display:inline-flex;align-items:center;padding:.2rem .6rem;border-radius:4px;color:#666;text-decoration:none;font-size:.85rem;background:rgba(0,0,0,0.05);transition:all .2s ease;height:24px}.pub-links a:hover{background:rgba(0,0,0,0.08);transform:translateY(-1px);color:#333}.pub-links i{margin-right:.3rem;font-size:.9rem}.abstract-toggle{cursor:pointer;user-select:none}.abstract-content{display:none}body.modal-open{overflow:hidden}.topic-filters{margin-bottom:2rem;display:flex;gap:.6rem;flex-wrap:wrap}.topic-filter{display:inline-flex;align-items:center;gap:.5rem;padding:.4rem 1rem;border-radius:30px;font-size:.9rem;cursor:pointer;transition:all .2s ease;border:2px solid transparent;user-select:none}.topic-filter span{font-family:"factoria",sans-serif;font-weight:500}.topic-filter i{font-size:1rem}.topic-filter.bio-learning,.topic-bio-learning .topic-icon{color:#e74694}.topic-filter.bio-learning{background:rgba(231,70,148,0.1);border-color:rgba(231,70,148,0.2)}.topic-filter.bio-learning.active{color:#d11b71;background:rgba(231,70,148,0.15);border-color:#d11b71;font-weight:600}.topic-filter.nas,.topic-nas .topic-icon{color:#3b82f6}.topic-filter.nas{background:rgba(59,130,246,0.1);border-color:rgba(59,130,246,0.2)}.topic-filter.nas.active{color:#1d4ed8;background:rgba(59,130,246,0.15);border-color:#1d4ed8;font-weight:600}.topic-filter.personality,.topic-personality .topic-icon{color:#10b981}.topic-filter.personality{background:rgba(16,185,129,0.1);border-color:rgba(16,185,129,0.2)}.topic-filter.personality.active{color:#047857;background:rgba(16,185,129,0.15);border-color:#047857;font-weight:600}.topic-filter.active{background:rgba(0,0,0,0.03)}.publication-item.topic-bio-learning{border-left-color:#e74694}.publication-item.topic-nas{border-left-color:#3b82f6}.publication-item.topic-personality{border-left-color:#10b981}.topic-filter.active{background:currentColor;border-color:currentColor;color:white}.publication-item.hidden{display:none}@media(max-width:768px){.publication-item{flex-direction:column;height:auto}.pub-image{width:160px;margin:0 auto 1rem auto}}.modal-overlay{display:none;position:fixed;top:0;left:0;right:0;bottom:0;z-index:1000}.modal{display:none;position:absolute;background:white;padding:1.2rem;border-radius:12px;max-width:600px;width:auto;max-height:150px;overflow-y:auto;box-shadow:0 4px 12px rgba(0,0,0,0.15);z-index:1001;transform-origin:top left}.modal.show{display:block;animation:popIn .2s cubic-bezier(0.34,1.56,0.64,1)}@keyframes popIn{from{opacity:0;transform:scale(0.6)}to{opacity:1;transform:scale(1)}}.modal::before{content:'';position:absolute;top:-8px;left:20px;width:16px;height:16px;background:white;transform:rotate(45deg);box-shadow:-2px -2px 5px rgba(0,0,0,0.06)}.modal-title{display:none}.modal-body{font-family:"proxima-nova",sans-serif;font-weight:300;font-size:.9rem;line-height:1.5;color:#4a5568;padding-right:.5rem;padding-top:.2rem}
.modal-close{position:absolute;top:.5rem;right:.5rem;width:1.5rem;height:1.5rem;border:0;background:0;color:#94a3b8;font-size:1.2rem;cursor:pointer;display:flex;align-items:center;justify-content:center;transition:color .2s ease}.modal-close:hover{color:#475569}.modal::-webkit-scrollbar{width:8px}.modal::-webkit-scrollbar-track{background:#f1f1f1;border-radius:4px}.modal::-webkit-scrollbar-thumb{background:#ccc;border-radius:4px}.modal::-webkit-scrollbar-thumb:hover{background:#bbb}</style> <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css"> <div class="topic-filters"> <div class="topic-filter bio-learning" data-topic="bio-learning"> <i class="fas fa-brain"></i> <span>Biologically inspired learning</span> </div> <div class="topic-filter nas" data-topic="nas"> <i class="fas fa-search"></i> <span>Neural architecture search</span> </div> <div class="topic-filter personality" data-topic="personality"> <i class="fas fa-robot"></i> <span>Computational personality</span> </div> </div> <script>document.addEventListener("DOMContentLoaded",function(){function t(){e.classList.remove("show"),o&&(document.removeEventListener("click",o),o=null),n=null}const e=document.createElement("div");e.className="modal",e.innerHTML='\n    <button class="modal-close">&times;</button>\n    <div class="modal-body"></div>\n  ',document.body.appendChild(e);let n=null,o=null;document.querySelectorAll(".abstract-toggle").forEach(s=>{s.addEventListener("click",function(s){if(s.preventDefault(),s.stopPropagation(),n===this&&e.classList.contains("show"))return void t();n=this;const c=this.closest(".publication-item").querySelector(".abstract-content").textContent.trim(),i=s.clientX,l=s.clientY+window.scrollY,a=600,d=window.innerWidth;let r=i-20;r+a>d&&(r=d-a-20),r=Math.max(20,r),e.style.left=`${r}px`,e.style.top=`${l+10}px`,e.style.transformOrigin=i-r+"px 0",e.querySelector(".modal-body").textContent=c,o&&document.removeEventListener("click",o),o=function(o){e.contains(o.target)||o.target===n||t()},e.classList.add("show"),setTimeout(()=>{document.addEventListener("click",o)},0)})}),e.querySelector(".modal-close").addEventListener("click",function(e){e.stopPropagation(),t()}),document.addEventListener("keydown",function(n){"Escape"===n.key&&e.classList.contains("show")&&t()});const s=document.querySelectorAll(".topic-filter"),c=document.querySelectorAll(".publication-item");let i=new Set;s.forEach(t=>{t.addEventListener("click",function(){const t=this.dataset.topic;this.classList.toggle("active"),this.classList.contains("active")?i.add(t):i.delete(t),c.forEach(t=>{if(0===i.size)t.classList.remove("hidden");else{const e=Array.from(i).some(e=>t.classList.contains(`topic-${e}`));t.classList.toggle("hidden",!e)}})})})});</script> <div class="modal-overlay"> <div class="modal"> <div class="modal-header"> <h3 class="modal-title"></h3> <button class="modal-close">Ã—</button> </div> <div class="modal-body"></div> </div> </div> <div class="publications"> <ol class="bibliography"> <li> <div class="publication-item topic-bio-learning"> <div class="pub-image"><img src="/assets/img/publication_preview/nodepert2025.png" alt="Preview of An Empirical Study of Perturbation Based Algorithms for Training Deep Networks"></div> <div class="pub-content"> <div class="title-row"> <div class="title"> An Empirical Study of Perturbation Based Algorithms for Training Deep Networks <span class="topic-icon" title="bio-learning"><i class="fas fa-brain"></i></span> </div> </div> <div class="author"> <em>Yash Mehta</em>,Â Naoki Hiratani,Â Peter Latham,Â Â andÂ Timothy Lillicrap</div> <div class="periodical"> <span class="venue"><em>In preparation</em></span> <span class="year">2025</span> </div> <div class="pub-links"> <span class="abstract-toggle" role="button" tabindex="0"> <i class="fas fa-chevron-right"></i> Abstract </span> <div class="abstract-content" aria-hidden="true"> We conduct a comprehensive empirical study of perturbation-based training algorithms, comparing their performance and properties across different network architectures and tasks. </div> <a href="https://github.com/silverpaths/nodepert" target="_blank" rel="noopener noreferrer"><i class="fas fa-code"></i>Code</a> </div> </div> </div> </li> <li> <div class="publication-item topic-bio-learning"> <div class="pub-image"><img src="/assets/img/publication_preview/plasticity2024.png" alt="Preview of Model-Based Inference of Synaptic Plasticity Rules"></div> <div class="pub-content"> <div class="title-row"> <div class="title"> Model-Based Inference of Synaptic Plasticity Rules <span class="topic-icon" title="bio-learning"><i class="fas fa-brain"></i></span> </div> </div> <div class="author"> <em>Yash Mehta</em>,Â Dan Tyulmankov,Â Adithya Rajagopalan,Â James Fitzgerald,Â Â andÂ Jan Funke</div> <div class="periodical"> <span class="venue"><em>Advances in Neural Information Processing Systems (NeurIPS)</em></span> <span class="year">2024</span> </div> <div class="pub-links"> <span class="abstract-toggle" role="button" tabindex="0"> <i class="fas fa-chevron-right"></i> Abstract </span> <div class="abstract-content" aria-hidden="true"> Synaptic plasticity, the ability of synapses to change their strength, is a key mechanism underlying learning in biological neural networks. However, inferring plasticity rules from neural recordings is challenging due to the complexity of biological networks and the difficulty of measuring synaptic weights directly. Here, we introduce a model-based approach to infer plasticity rules from neural activity alone, without requiring direct measurement of synaptic weights. </div> <a href="https://www.biorxiv.org/content/10.1101/2023.12.11.571103v2" target="_blank" rel="noopener noreferrer"><i class="fas fa-file-pdf"></i>PDF</a> <a href="https://github.com/yashsmehta/MetaLearnPlasticity" target="_blank" rel="noopener noreferrer"><i class="fas fa-code"></i>Code</a> <a href="https://yashsmehta.com/plasticity-paper-website/" target="_blank" rel="noopener noreferrer"><i class="fas fa-globe"></i>Website</a> </div> </div> </div> </li> <li> <div class="publication-item topic-bio-learning"> <div class="pub-image"><img src="/assets/img/publication_preview/nodepert2022.png" alt="Preview of Stability and Scalability of Node Perturbation Learning"></div> <div class="pub-content"> <div class="title-row"> <div class="title"> Stability and Scalability of Node Perturbation Learning <span class="topic-icon" title="bio-learning"><i class="fas fa-brain"></i></span> </div> </div> <div class="author">Naoki Hiratani,Â <em>Yash Mehta</em>,Â Timothy Lillicrap,Â Â andÂ Peter Latham</div> <div class="periodical"> <span class="venue"><em>Advances in Neural Information Processing Systems (NeurIPS)</em></span> <span class="year">2022</span> </div> <div class="pub-links"> <span class="abstract-toggle" role="button" tabindex="0"> <i class="fas fa-chevron-right"></i> Abstract </span> <div class="abstract-content" aria-hidden="true"> We analyze the theoretical properties of node perturbation learning, providing new insights into its stability and scaling behavior in deep neural networks. </div> <a href="https://openreview.net/forum?id=X0CKM7QV5k" target="_blank" rel="noopener noreferrer"><i class="fas fa-file-pdf"></i>PDF</a> <a href="https://github.com/silverpaths/nodepert" target="_blank" rel="noopener noreferrer"><i class="fas fa-code"></i>Code</a> </div> </div> </div> </li> <li> <div class="publication-item topic-nas"> <div class="pub-image"><img src="/assets/img/publication_preview/nasbench2022.png" alt="Preview of NAS-Bench-Suite: NAS Evaluation is (Now) Surprisingly Easy"></div> <div class="pub-content"> <div class="title-row"> <div class="title"> NAS-Bench-Suite: NAS Evaluation is (Now) Surprisingly Easy <span class="topic-icon" title="nas"><i class="fas fa-search"></i></span> </div> </div> <div class="author"> <em>Yash Mehta</em>,Â Colin White,Â Arber Zela,Â Arjun Krishnakumar,Â Guri Zabergja,Â Shakiba Moradian,Â Mahmoud Safari,Â Â andÂ Frank Hutter</div> <div class="periodical"> <span class="venue"><em>International Conference on Learning Representations (ICLR)</em></span> <span class="year">2022</span> </div> <div class="pub-links"> <span class="abstract-toggle" role="button" tabindex="0"> <i class="fas fa-chevron-right"></i> Abstract </span> <div class="abstract-content" aria-hidden="true"> We introduce NAS-Bench-Suite, a unified interface to popular Neural Architecture Search (NAS) benchmarks, making NAS research more accessible and reproducible while significantly reducing computational costs. </div> <a href="https://arxiv.org/pdf/2201.13396.pdf" target="_blank" rel="noopener noreferrer"><i class="fas fa-file-pdf"></i>PDF</a> <a href="https://github.com/automl/NASLib" target="_blank" rel="noopener noreferrer"><i class="fas fa-code"></i>Code</a> </div> </div> </div> </li> <li> <div class="publication-item topic-personality"> <div class="pub-image"><img src="/assets/img/publication_preview/fgcs2022.jpg" alt="Preview of Future-generation Personality Prediction from Digital Footprints"></div> <div class="pub-content"> <div class="title-row"> <div class="title"> Future-generation Personality Prediction from Digital Footprints <span class="topic-icon" title="personality"><i class="fas fa-robot"></i></span> </div> </div> <div class="author"> <em>Yash Mehta</em>,Â Clemens Stachl,Â Konstantin Markov,Â Joseph T Yun,Â Â andÂ BjÃ¶rn W Schuller</div> <div class="periodical"> <span class="venue"><em>Future Generation Computer Systems</em></span> <span class="year">2022</span> </div> <div class="pub-links"> <span class="abstract-toggle" role="button" tabindex="0"> <i class="fas fa-chevron-right"></i> Abstract </span> <div class="abstract-content" aria-hidden="true"> This paper discusses emerging trends and challenges in personality prediction from digital footprints, focusing on ethical considerations and future directions for the field. </div> <a href="https://www.sciencedirect.com/journal/future-generation-computer-systems/special-issue/104WJNQCXFX" target="_blank" rel="noopener noreferrer"><i class="fas fa-globe"></i>Website</a> </div> </div> </div> </li> <li> <div class="publication-item topic-bio-learning"> <div class="pub-image"><img src="/assets/img/publication_preview/bioconv2021.png" alt="Preview of Towards Biologically Plausible Convolutional Networks"></div> <div class="pub-content"> <div class="title-row"> <div class="title"> Towards Biologically Plausible Convolutional Networks <span class="topic-icon" title="bio-learning"><i class="fas fa-brain"></i></span> </div> </div> <div class="author">Roman Pogodin,Â <em>Yash Mehta</em>,Â Timothy Lillicrap,Â Â andÂ Peter Latham</div> <div class="periodical"> <span class="venue"><em>Advances in Neural Information Processing Systems (NeurIPS)</em></span> <span class="year">2021</span> </div> <div class="pub-links"> <span class="abstract-toggle" role="button" tabindex="0"> <i class="fas fa-chevron-right"></i> Abstract </span> <div class="abstract-content" aria-hidden="true"> We develop a biologically plausible implementation of convolutional networks that maintains the computational advantages of weight sharing while respecting biological constraints on neural connectivity. </div> <a href="https://proceedings.neurips.cc/paper/2021/file/746b02b6680562f44ad7526675bac026-Paper.pdf" target="_blank" rel="noopener noreferrer"><i class="fas fa-file-pdf"></i>PDF</a> <a href="https://github.com/romanpogodin/towards-bio-plausible-conv" target="_blank" rel="noopener noreferrer"><i class="fas fa-code"></i>Code</a> </div> </div> </div> </li> <li> <div class="publication-item topic-personality"> <div class="pub-image"><img src="/assets/img/publication_preview/personality2020.png" alt="Preview of Recent Trends in Deep Learning Based Personality Detection"></div> <div class="pub-content"> <div class="title-row"> <div class="title"> Recent Trends in Deep Learning Based Personality Detection <span class="topic-icon" title="personality"><i class="fas fa-robot"></i></span> </div> </div> <div class="author"> <em>Yash Mehta</em>,Â Navonil Majumder,Â Alexander Gelbukh,Â Â andÂ Erik Cambria</div> <div class="periodical"> <span class="venue"><em>Artificial Intelligence Review</em></span> <span class="year">2020</span> </div> <div class="pub-links"> <span class="abstract-toggle" role="button" tabindex="0"> <i class="fas fa-chevron-right"></i> Abstract </span> <div class="abstract-content" aria-hidden="true"> This survey provides a comprehensive overview of personality detection methods using deep learning, covering recent advances in computational personality recognition and discussing future research directions. </div> <a href="https://link.springer.com/article/10.1007/s10462-019-09770-z" target="_blank" rel="noopener noreferrer"><i class="fas fa-file-pdf"></i>PDF</a> </div> </div> </div> </li> <li> <div class="publication-item topic-personality"> <div class="pub-image"><img src="/assets/img/publication_preview/personality_icdm2020.png" alt="Preview of Bottom-Up and Top-Down: Predicting Personality with Psycholinguistic and Language Model Features"></div> <div class="pub-content"> <div class="title-row"> <div class="title"> Bottom-Up and Top-Down: Predicting Personality with Psycholinguistic and Language Model Features <span class="topic-icon" title="personality"><i class="fas fa-robot"></i></span> </div> </div> <div class="author"> <em>Yash Mehta</em>,Â Samin Fatehi,Â Amirmohammad Kazameini,Â Clemens Stachl,Â Â andÂ Erik Cambria</div> <div class="periodical"> <span class="venue"><em>IEEE International Conference on Data Mining (ICDM)</em></span> <span class="year">2020</span> </div> <div class="pub-links"> <span class="abstract-toggle" role="button" tabindex="0"> <i class="fas fa-chevron-right"></i> Abstract </span> <div class="abstract-content" aria-hidden="true"> This paper introduces a novel two-stream architecture that combines psycholinguistic features with deep language model representations for improved personality prediction from text data. </div> <a href="https://ieeexplore.ieee.org/document/9338428" target="_blank" rel="noopener noreferrer"><i class="fas fa-file-pdf"></i>PDF</a> <a href="https://github.com/yashsmehta/personality-prediction" target="_blank" rel="noopener noreferrer"><i class="fas fa-code"></i>Code</a> </div> </div> </div> </li> <li> <div class="publication-item topic-personality"> <div class="pub-image"><img src="/assets/img/publication_preview/personality_bert2020.png" alt="Preview of Personality Trait Detection Using Bagged SVM over BERT Word Embedding Ensembles"></div> <div class="pub-content"> <div class="title-row"> <div class="title"> Personality Trait Detection Using Bagged SVM over BERT Word Embedding Ensembles <span class="topic-icon" title="personality"><i class="fas fa-robot"></i></span> </div> </div> <div class="author">Amirmohammad Kazameini,Â Samin Fatehi,Â <em>Yash Mehta</em>,Â Sauleh Eetemadi,Â Â andÂ Erik Cambria</div> <div class="periodical"> <span class="venue"><em>ACL Workshop on Widening NLP (WiNLP)</em></span> <span class="year">2020</span> </div> <div class="pub-links"> <span class="abstract-toggle" role="button" tabindex="0"> <i class="fas fa-chevron-right"></i> Abstract </span> <div class="abstract-content" aria-hidden="true"> We propose a novel approach combining BERT embeddings with bagged SVM classifiers for robust personality trait detection from text, achieving state-of-the-art results on standard benchmarks. </div> <a href="https://github.com/yashsmehta/personality-prediction" target="_blank" rel="noopener noreferrer"><i class="fas fa-code"></i>Code</a> </div> </div> </div> </li> <li> <div class="publication-item topic-personality"> <div class="pub-image"><img src="/assets/img/publication_preview/mtl2020.png" alt="Preview of Multitask Learning for Emotion and Personality Detection"></div> <div class="pub-content"> <div class="title-row"> <div class="title"> Multitask Learning for Emotion and Personality Detection <span class="topic-icon" title="personality"><i class="fas fa-robot"></i></span> </div> </div> <div class="author">Yang Li,Â Amirmohammad Kazameini,Â <em>Yash Mehta</em>,Â Â andÂ Erik Cambria</div> <div class="periodical"> <span class="venue"><em>Neurocomputing</em></span> <span class="year">2020</span> </div> <div class="pub-links"> <span class="abstract-toggle" role="button" tabindex="0"> <i class="fas fa-chevron-right"></i> Abstract </span> <div class="abstract-content" aria-hidden="true"> We present a multitask learning framework that jointly learns to predict emotions and personality traits, showing how these related tasks can benefit from shared representations. </div> <a href="https://www.sciencedirect.com/science/article/pii/S0925231222004180" target="_blank" rel="noopener noreferrer"><i class="fas fa-file-pdf"></i>PDF</a> <a href="https://github.com/npuliyang/Personality-Detection-MTL" target="_blank" rel="noopener noreferrer"><i class="fas fa-code"></i>Code</a> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <style>@import url('https://fonts.googleapis.com/css2?family=Dancing+Script:wght@500&display=swap');footer{min-height:unset!important;padding:0!important}footer .container{padding:12px!important;line-height:1.2!important;text-align:center}.footer-quote{font-family:'Dancing Script',cursive;font-size:1.2rem;color:#666}@media(max-width:768px){.footer-quote{font-size:.95rem}footer .container{box-sizing:border-box!important;max-width:100%!important;overflow-wrap:break-word}}</style> <footer class="sticky-bottom mt-5"> <div class="container"> <span class="footer-quote">Live for the moments you can't put into words</span> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-8RFCFYW3FP"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-8RFCFYW3FP");</script> <script>document.addEventListener("DOMContentLoaded",function(){function t(){s.width=window.innerWidth,s.height=window.innerHeight}function i(){h.clearRect(0,0,s.width,s.height),r.forEach(t=>{t.update(),t.draw()});for(let t=0;t<r.length;t++)for(let i=t+1;i<r.length;i++){const s=r[t].x-r[i].x,e=r[t].y-r[i].y,n=Math.sqrt(s*s+e*e);if(n<a){const s=1-n/a,e=!o.isOverContent&&Math.sqrt(Math.pow(o.x-r[t].x,2)+Math.pow(o.y-r[t].y,2))<120,l=!o.isOverContent&&Math.sqrt(Math.pow(o.x-r[i].x,2)+Math.pow(o.y-r[i].y,2))<120,d=e||l?`rgba(0, 45, 114, ${.5*s})`:`rgba(104, 172, 229, ${.35*s})`;h.strokeStyle=d,h.lineWidth=e||l?1.5:1,h.beginPath(),h.moveTo(r[t].x,r[t].y),h.lineTo(r[i].x,r[i].y),h.stroke()}}requestAnimationFrame(i)}const s=document.getElementById("network-animation"),h=s.getContext("2d"),e=document.querySelector(".container.mt-5");let o={x:void 0,y:void 0,isOverContent:!1};document.addEventListener("mousemove",function(t){o.x=t.clientX,o.y=t.clientY;const i=e.getBoundingClientRect(),s=window.scrollY;o.isOverContent=t.clientX>=i.left&&t.clientX<=i.right&&t.clientY+s>=i.top+s&&t.clientY+s<=i.bottom+s}),t(),window.addEventListener("resize",t);class n{constructor(){this.x=Math.random()*s.width,this.y=Math.random()*s.height,this.vx=.8*(Math.random()-.5),this.vy=.8*(Math.random()-.5),this.baseRadius=3,this.radius=this.baseRadius,this.color="rgba(104, 172, 229, 0.75)",this.highlightColor="rgba(0, 45, 114, 0.9)",this.currentColor=this.color}update(){if(this.x+=this.vx,this.y+=this.vy,(this.x<0||this.x>s.width)&&(this.vx*=-1),(this.y<0||this.y>s.height)&&(this.vy*=-1),o.isOverContent)return this.radius=this.baseRadius,void(this.currentColor=this.color);const t=o.x-this.x,i=o.y-this.y,h=Math.sqrt(t*t+i*i),e=120;if(h<e){const s=1-h/e;this.radius=this.baseRadius+2*s,this.currentColor=this.highlightColor,this.vx+=t/h*.02,this.vy+=i/h*.02}else this.radius=this.baseRadius,this.currentColor=this.color;const n=1.5,r=Math.sqrt(this.vx*this.vx+this.vy*this.vy);r>n&&(this.vx=this.vx/r*n,this.vy=this.vy/r*n)}draw(){h.beginPath(),h.arc(this.x,this.y,this.radius,0,2*Math.PI),h.fillStyle=this.currentColor,h.fill(),h.beginPath(),h.arc(this.x,this.y,this.radius+2,0,2*Math.PI),h.fillStyle=`rgba(104, 172, 229, ${this.currentColor===this.highlightColor?.1:.05})`,h.fill()}}const r=Array(100).fill().map(()=>new n),a=150;i()});</script> </body> </html>